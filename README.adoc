Showcase Emob
-------------

Requirements
~~~~~~~~~~~~

The following Kafka connectors are required:

- MQTT connector: https://www.confluent.io/hub/confluentinc/kafka-connect-mqtt 
- MongoDB connector: https://www.confluent.io/hub/mongodb/kafka-connect-mongodb
- Debezium MongoDB CDC Connector: https://www.confluent.io/hub/debezium/debezium-connector-mongodb

clone the git-repository
----
cd ./showcase
docker-compose down
rm docker-compose.yml
cd ..
git clone https://github.com/NovatecConsulting/technologyconsulting-showcase-emob.git
----

Create the showcase network
----
docker network create showcase_emob
----


Quickstart
~~~~~~~~~~
.Change in the showcase directory, create the following subfolder _/connectors/jars_ and extract the downloaded connectors to it.
----
cd ./technologyconsulting-showcase-emob
----

.To start and setup the environment in one step run:
----
./startup-and-setup.sh
----
.Note that it could take a while until the connect service is healthy (~about 5-10 minutes)

.To start the showcase from the base directory of the showcase (technologyconsulting-showcase-emob) and do the configuration in separate single tasks perform the following
----
docker-compose up -d
or if you want to see the output on the console
docker-compose up 
----

.Wait until all components and modules (especially) _connect_ are up. Verify with 
----
docker-compose ps
----

.Configure the MQTT and MongoDB connectors and KSQL query. Verify that the following shell-scripts: setup.sh, setup-createtopics.sh, setup-connectors.sh, setup-ksqlquery.sh are executable by chmod +x
----
chmod +x setup.sh
./setup.sh
----

.Publish test data to HiveMQ (chmod +x if necessary)
----
chmod +x test-connect.sh
./test-connect.sh
----

* The test publishes some sample messages to different topics e.g. _CIQ000000017/out/charge_ _CIQ000000012/out/blink_ on HiveMQ broker. 
* These messages are imported to Kafka topic _wallbox_source_ with _mqtt-source_ connector. This topic can be inspected from control center http://localhost:9021/.
* The stream processor defined by the KSQL query reads imported record in _wallbox_source_, applies avro schema to it and rewrites this new record from _+/out/charge_ to topic _wallbox_charge_. 
* The records in _wallbox_charge_ are exported to MongoDB with _mongodb-sink_ connector. The MongoDB can be inspected with MongoDB client on _localhost:3000_. On MongoDB client, connect to MongoDB using the _Default (preconfigured)_ connection. The exported record is in collection _ChargingStations_.
* Records in _wallbox_charge_ are copied to the compacted topic _wallbox_chargestatus_ to retain only the latest status for each station. 
* Locations of stations in mongoDB (which are inserted to mongoDB when starting up the showcase) are imported into Kafka topic _wallbox_location_ with _mongodb-source_ connector. 
* _wallbox_location_ and _wallbox_chargestatus_ are joined with KSQL to create enriched records of _wallbox_location_chargestatus_.

.To test the setup-procedure you can invoke a kafka-console-consumer
----
kafka-console-consumer --bootstrap-server localhost:19092 --topic wallbox_source --from-beginning
----

.To test the avro schema topics you can use the kafka-avro-console-consumer
----
kafka-avro-console-consumer --bootstrap-server localhost:19092 \
    --property schema.registry.url=http://schema-registry:8081 \
    --topic wallbox_location_chargestatus --property print.key=true \
    --key-deserializer=org.apache.kafka.common.serialization.StringDeserializer \
    --from-beginning
----  

.Stop the showcase 
----
docker-compose down
----

Overview of Components
~~~~~~~~~~~~~~~~~~~~~~

The showcase is using the following Kafka components as described in the picture below:

image::Kafka_cluster_diagram_v3.svg[]



Data Flow between Topics and Ksql Streams/Tables
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

image::DataFlow_v2.svg[]

Using Node-RED for Simulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can Use the Flow-Simulation in Node-RED to simulate charging Events of electric vehicles (ev)
By importing the _connectIQ_MQTT_sim.json_ into the browser  http://localhost:1880/  based view and deploying the flow.
You can send (and receive) MQTT messages to the MQTT-Broker (HiveMQ). Node-RED simulates the Edge-Environment.

Network and Credentials
~~~~~~~~~~~~~~~~~~~~~~~

[options="header"]
.Credentials
|===
| Service | Username | Password
| hivemq  | admin    | hivemq
|===


[cols="h,1"]
.Access to services from host
|===
| Kafka Bootstrap Server|  localhost:9092
| Schema Registry Url | localhost:8081
| Confluent Control Center | localhost:9021 
| Kafka Connect | localhost:8083
| KSQL server   | localhost:8088
| HiveMQ Broker | localhost:8080
| MongoDB client| localhost:3000
| Node-RED      | localhost:1880
|===


