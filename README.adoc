Showcase Emob
-------------

Requirements
~~~~~~~~~~~~

clone the git-repository
----
git clone https://github.com/NovatecConsulting/technologyconsulting-showcase-emob.git
----

This project uses a local setup based on Docker-Compose. Therefore, in order to run this showcase on your
local machine, you need Docker and Docker-Compose which at least supports the Docker-Compose file format 2.4.

Quickstart
~~~~~~~~~~

.Change in the showcase directory
----
cd ./technologyconsulting-showcase-emob
----

.To start the infrastructure services, deploy the application (topic creation, connectors and ksqlDB statement deployment) and import the test data in one step, run: 
----
./emob-dc.sh start all
----
.Note that this could take serveral minutes

In the following it is described how you can do this step by step:

.To start the showcase from the base directory of the showcase (technologyconsulting-showcase-emob) and do the configuration in separate single tasks perform the following
----
./emob-dc.sh start infra
----

.Alternatively you can still use docker-compose directly (in order to start the single instance setup):
----
docker-compose up -d
# or if you want to see the output on the console
docker-compose up 
----

.You can check the health of the services with:
----
./emob-dc.sh ps
# or with plain docker-compose
docker-compose ps
----

.The startup command blocks until all services are healthy. After this you can deploy the app (which includes topic creation, connectors and ksqlDB statement deployment):
----
./emob-dc.sh start deploy
----

.Finally you can publish test data to HiveMQ
----
./emob-dc.sh start testdata
----

* The test publishes some sample messages to different topics e.g. _CIQ000000017/out/charge_ _CIQ000000012/out/blink_ on HiveMQ broker. 
* These messages are imported to Kafka topic _wallbox_source_ with _mqtt-source_ connector. This topic can be inspected from control center http://localhost:9021/.
* The stream processor defined by the KSQL query reads imported record in _wallbox_source_, applies avro schema to it and rewrites this new record from _+/out/charge_ to topic _wallbox_charge_. 
* The records in _wallbox_charge_ are exported to MongoDB with _mongodb-sink_ connector. The MongoDB can be inspected with MongoDB client on _localhost:3000_. On MongoDB client, connect to MongoDB using the _Default (preconfigured)_ connection. The exported record is in collection _ChargingStations_.
* Records in _wallbox_charge_ are copied to the compacted topic _wallbox_chargestatus_ to retain only the latest status for each station. 
* Locations of stations in mongoDB (which are inserted to mongoDB when starting up the showcase) are imported into Kafka topic _wallbox_location_ with _mongodb-source_ connector. 
* _wallbox_location_ and _wallbox_chargestatus_ are joined with KSQL to create enriched records of _wallbox_location_chargestatus_.

.To test the setup-procedure you can invoke a kafka-console-consumer
----
kafka-console-consumer --bootstrap-server localhost:19092 --topic wallbox_source --from-beginning
----

.To test the avro schema topics you can use the kafka-avro-console-consumer
----
kafka-avro-console-consumer --bootstrap-server localhost:19092 \
    --property schema.registry.url=http://schema-registry:8081 \
    --topic wallbox_location_chargestatus --property print.key=true \
    --key-deserializer=org.apache.kafka.common.serialization.StringDeserializer \
    --from-beginning
----  

.Stop the showcase 
----
./emob-dc.sh down
docker-compose down -v --remove-orphans
----

Overview of Components
~~~~~~~~~~~~~~~~~~~~~~

The showcase is using the following Kafka components as described in the picture below:

image::Kafka_cluster_diagram_v3.svg[]



Data Flow between Topics and Ksql Streams/Tables
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

image::DataFlow_v2.svg[]

Using Node-RED for Simulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can Use the Flow-Simulation in Node-RED to simulate charging Events of electric vehicles (ev)
By importing the _connectIQ_MQTT_sim.json_ into the browser  http://localhost:1880/  based view and deploying the flow.
You can send (and receive) MQTT messages to the MQTT-Broker (HiveMQ). Node-RED simulates the Edge-Environment.

Network and Credentials
~~~~~~~~~~~~~~~~~~~~~~~

[options="header"]
.Credentials
|===
| Service | Username | Password
| hivemq  | admin    | hivemq
|===


[cols="h,1"]
.Access to services from host
|===
| Kafka Bootstrap Server|  localhost:9092
| Schema Registry Url | localhost:8081
| Confluent Control Center | localhost:9021 
| Kafka Connect | localhost:8083
| KSQL server   | localhost:8088
| HiveMQ Broker | localhost:8080
| MongoDB client| localhost:3000
| Node-RED      | localhost:1880
|===

Kafka Connect Connectors
~~~~~~~~~~~~~~~~~~~~~~~~

The following Kafka connectors are used by the showcase:

- MQTT connector: https://www.confluent.io/hub/confluentinc/kafka-connect-mqtt 
- MongoDB connector: https://www.confluent.io/hub/mongodb/kafka-connect-mongodb
- Debezium MongoDB CDC Connector: https://www.confluent.io/hub/debezium/debezium-connector-mongodb

The required connectors are automatically downloaded and installed, when the Docker image for connect is created.
Which connectors are to be installed is specified in the Docker-Compose file.

----
connect:
  image: novatec/cp-kafka-connect-emob:${VERSION_CONFLUENT}
  build:
    context: .
    dockerfile: Dockerfile.connect
    args:
      VERSION_CONFLUENT: ${VERSION_CONFLUENT}
      CONNECTORS: |-
        confluentinc/kafka-connect-mqtt:1.3.0
        confluentinc/kafka-connect-jdbc:5.5.1
        mongodb/kafka-connect-mongodb:1.2.0
        debezium/debezium-connector-mongodb:1.2.2
----

If a connector is added or removed, the image can be rebuilt with the command `docker-compse build connect`.